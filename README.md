# Adaptive Trust in Multi-Agent Systems

## Introduction 

Trust is a fundamental concern in large-scale open distributed systems. It lies at the core of all interactions between the entities that have to operate in such uncertain and constantly changing environments. Given this complexity, these components and the ensuing system are increasingly being conceptualised, designed, and built using agent-based techniques. 

Cooperation within multi-agent systems has seen much attention in the research community due to the potential for increased performance over single agent systems when applied to information sharing in order to reach a specific goal. As agents are deployed in a workspace that is shared with other agents, there is no reason to assume that all agents within the workspace are trustworthy. The possibility for agents to compete, misinform and mislead one another exists. In the context of information sharing within a multi-agent system involving dishonest agents, an agent may have to evaluate the trustworthiness of other agents to select one to select one to interact with. 

## Objective of the project 

The provided trust model is applied to a concrete example consisting of a trust market affording agents the quality estimation of other agents services based on the feedback outcome of their matesâ€™ previous interactions. The credibility of witnesses as well as certainty regarding provided information  are used to appraise the indirect reputation. Then, we produce some simulations based on the model introduced previously, with the aim of appraising to what extent the outcome meets the results desired. 
